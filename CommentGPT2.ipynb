{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "CommentGPT2",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YGfubih3VCV_V1GbJPraL4j_As2TMREj",
      "authorship_tag": "ABX9TyOlrcfmL5qzP/Np5lowDZ2d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaveRipper/CommentGPT2/blob/master/CommentGPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKnc0ctgAwC"
      },
      "source": [
        "!git clone https://github.com/daveripper/commentgpt2\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install pytorch_lightning==1.2.10\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaDFy8xGGs5P",
        "outputId": "513baa53-d928-4b65-8b96-b788e3fae4fd"
      },
      "source": [
        "cd /content/commentgpt2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/commentgpt2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYZ5BkdUGu19"
      },
      "source": [
        "!python train.py --train --batch-size 96 --default_root_dir \"/content/drive/MyDrive/CommentGPT2/\" --dataset_path \"/content/commentgpt2/data.txt\" --tpu_cores 8 --max-len 32 --max_epochs 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpkoQHQbPtF-",
        "outputId": "85cf6138-4e0c-4c0d-ab9d-cb965e369e5d"
      },
      "source": [
        "!python train.py --generate --inputs \"하\" --model_params \"/content/drive/MyDrive/CommentGPT2/lightning_logs/version_0/checkpoints/model_-last.ckpt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.8\n",
            "INFO:root:Namespace(accelerator=None, accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=96, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, dataset_path='NONE', default_root_dir=None, deterministic=False, distributed_backend=None, enable_pl_optimizer=None, fast_dev_run=False, flush_logs_every_n_steps=100, generate=True, gpus=None, gradient_clip_val=0, inputs='하', limit_predict_batches=1.0, limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=5e-05, max_epochs=None, max_len=32, max_steps=None, min_epochs=None, min_steps=None, model_params='/content/drive/MyDrive/CommentGPT2/lightning_logs/version_0/checkpoints/model_-last.ckpt', move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=1, num_sanity_val_steps=2, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, stochastic_weight_avg=False, sync_batchnorm=False, terminate_on_nan=False, tpu_cores=None, track_grad_norm=-1, train=False, truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
            "1: 하 친일 올가미가 아니라 니네년이 할말아니다.\n",
            "\n",
            "2: 하 이쓰레기들이 발악을 하는 걸로 보인다 5.친일파재산환수법 반대-자한당 태극기\n",
            "\n",
            "3: 하 친일파의 후예들이 이런 소리를 하니까 가슴이 철렁 내려앉는구나.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}